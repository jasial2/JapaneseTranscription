{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOtnOOmv3yHDjytuzuWG6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasial2/JapaneseTranscription/blob/main/DWT_Transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Added 'onnxruntime-gpu' to fix the VAD warning and speed up processing\n",
        "!pip install whisper-timestamped srt ffmpeg-python tqdm onnxruntime-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zFph6vQ3S8Lg",
        "outputId": "69500159-ac4f-4087-b47b-d15ade226c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisper-timestamped\n",
            "  Downloading whisper_timestamped-1.15.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting srt\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (3.0.12)\n",
            "Collecting dtw-python (from whisper-timestamped)\n",
            "  Downloading dtw_python-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting openai-whisper (from whisper-timestamped)\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from dtw-python->whisper-timestamped) (1.16.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (2.9.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->whisper-timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2025.11.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper->whisper-timestamped) (3.0.3)\n",
            "Downloading whisper_timestamped-1.15.9-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dtw_python-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt, openai-whisper\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=9fba121bc011e4d7d4fdd9e9d29bb6851547f244594c30105322533cbfd900be\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/75/5b/e1d5c3756631e4bda806f6cc9640153b39484bb6f7b0b8def3\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=ed51459fb910f3a8fd22664ac40c926378c4e80508c8cfecb9fe71c11503898e\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built srt openai-whisper\n",
            "Installing collected packages: srt, humanfriendly, ffmpeg-python, dtw-python, coloredlogs, onnxruntime-gpu, openai-whisper, whisper-timestamped\n",
            "Successfully installed coloredlogs-15.0.1 dtw-python-1.7.2 ffmpeg-python-0.2.0 humanfriendly-10.0 onnxruntime-gpu-1.23.2 openai-whisper-20250625 srt-3.5.3 whisper-timestamped-1.15.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: SETUP & IMPORTS ---\n",
        "import whisper_timestamped as whisper\n",
        "import torch\n",
        "import os\n",
        "import srt\n",
        "import datetime\n",
        "import ffmpeg\n",
        "import re\n",
        "import sys\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- FIX: SUPPRESS TORCH HUB WARNINGS ---\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.hub\")\n",
        "\n",
        "# --- MISSING PART: DEFINE DEVICE ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRzA7Rtvggsh",
        "outputId": "c27b6652-26f6-47e5-9be4-83e014056ca2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing the dtw module. When using in academic works please cite:\n",
            "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
            "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
            "\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "# Note: 'large-v3' is usually better for timestamps than 'turbo', but 'turbo' is faster.\n",
        "print(\"Loading model...\")\n",
        "model = whisper.load_model(\"turbo\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DVWz4VZKSNJ_",
        "outputId": "0c9436fa-ed0c-4272-d074-d789dd6d8f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.51G/1.51G [00:11<00:00, 145MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "input_video = \"1234.mp3\"  # <--- REPLACE THIS WITH YOUR FILE\n",
        "output_srt = \"output.srt\"\n",
        "language = \"ja\"\n",
        "\n",
        "# --- HELPER: AUDIO PROCESSING ---\n",
        "processed_audio = \"temp_clean_audio.wav\"\n",
        "\n",
        "if not os.path.exists(input_video):\n",
        "    raise FileNotFoundError(f\"File '{input_video}' not found! Upload it to the Files tab.\")\n",
        "\n",
        "print(f\"1. Optimizing audio for Voice Frequencies ({input_video})...\")\n",
        "try:\n",
        "    # highpass=100: Removes rumble. lowpass=8000: Removes hiss.\n",
        "    # ar=16000: Whisper requires 16kHz.\n",
        "    (\n",
        "        ffmpeg.input(input_video)\n",
        "        .output(processed_audio, acodec=\"pcm_s16le\", ac=1, ar=\"16000\", af=\"highpass=f=100,lowpass=f=8000\")\n",
        "        .overwrite_output()\n",
        "        .run(quiet=True)\n",
        "    )\n",
        "except ffmpeg.Error as e:\n",
        "    print(\"FFmpeg error:\", e.stderr)\n",
        "    raise\n",
        "\n",
        "# --- 2. RUN WHISPER-TIMESTAMPED (The Sync Fix) ---\n",
        "print(\"2. Transcribing with Forced Alignment (DTW)...\")\n",
        "\n",
        "# Configuration for Sync Accuracy\n",
        "result = whisper.transcribe(\n",
        "    model,\n",
        "    processed_audio,\n",
        "    language=language,\n",
        "\n",
        "    # --- SYNC SETTINGS ---\n",
        "    beam_size=5,\n",
        "    best_of=5,\n",
        "    temperature=0.0,\n",
        "\n",
        "    # CRITICAL: Forces alignment to audio waves, fixing the \"out of sync\" issue\n",
        "    trust_whisper_timestamps=False,\n",
        "\n",
        "    # Helps ignore silence/breathing so timestamps don't drift\n",
        "    vad=False,\n",
        "\n",
        "    # Detects hesitancy (uh, um) separately (optional, helps precision)\n",
        "    detect_disfluencies=True,\n",
        "\n",
        "    # Standard settings\n",
        "    condition_on_previous_text=False,\n",
        "    initial_prompt=\"うめき声や呼吸音を無視して、会話のみを書き起こしてください。\"\n",
        ")\n",
        "\n",
        "# --- 3. ADVANCED FILTERING ---\n",
        "print(\"3. Applying Japanese Garbage & Duration Filters...\")\n",
        "\n",
        "# A. Hallucination Triggers\n",
        "hallucination_triggers = [\n",
        "    \"thank you for watching\", \"thanks for watching\", \"please subscribe\",\n",
        "    \"subscribe\", \"sub by\", \"translated by\", \"amara\", \"viewing\",\n",
        "    \"see you next\", \"bye\", \"the end\", \"like and\", \"follow me\",\n",
        "    \"字幕\", \"視聴\", \"チャンネル\", \"登録\", \"高評価\"\n",
        "]\n",
        "\n",
        "# B. Garbage Sounds\n",
        "garbage_exact_matches = {\n",
        "    # English\n",
        "    \"a\", \"aa\", \"ah\", \"ahh\", \"ha\", \"haa\", \"hah\", \"haha\",\n",
        "    \"mm\", \"mmm\", \"hmm\", \"mh\", \"oh\", \"huh\", \"o\", \"m\",\n",
        "    \"h\", \"eh\", \"uh\", \"uhh\",\n",
        "    # Japanese\n",
        "    \"あ\", \"ああ\", \"あっ\", \"あー\",\n",
        "    \"ん\", \"んん\", \"んっ\", \"う\", \"うっ\",\n",
        "    \"は\", \"はぁ\", \"はあ\", \"ふ\", \"ふぅ\",\n",
        "    \"く\", \"くっ\", \"や\", \"いや\", \"お\", \"おっ\"\n",
        "}\n",
        "\n",
        "final_subs = []\n",
        "sub_index = 1\n",
        "\n",
        "for segment in result[\"segments\"]:\n",
        "    text = segment[\"text\"].strip()\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # 1. DURATION CHECK\n",
        "    # Check strict duration to remove noise\n",
        "    duration = segment[\"end\"] - segment[\"start\"]\n",
        "    if duration < 0.4:\n",
        "        continue\n",
        "\n",
        "    # 2. HALLUCINATION CHECK\n",
        "    if any(h in text_lower for h in hallucination_triggers):\n",
        "        continue\n",
        "\n",
        "    # 3. GARBAGE CHECK\n",
        "    clean_text = re.sub(r'[^\\w\\s]', '', text_lower) # Remove punctuation\n",
        "    words = clean_text.split()\n",
        "\n",
        "    if len(words) == 0:\n",
        "        continue\n",
        "\n",
        "    # Check if ALL words are garbage\n",
        "    is_pure_garbage = True\n",
        "    for w in words:\n",
        "        if w not in garbage_exact_matches:\n",
        "            is_pure_garbage = False\n",
        "            break\n",
        "\n",
        "    if is_pure_garbage:\n",
        "        continue\n",
        "\n",
        "    # 4. REPETITION CHECK\n",
        "    if len(words) > 4 and len(set(words)) == 1:\n",
        "        continue\n",
        "\n",
        "    # Add to subtitles\n",
        "    final_subs.append(\n",
        "        srt.Subtitle(\n",
        "            index=sub_index,\n",
        "            start=datetime.timedelta(seconds=segment[\"start\"]),\n",
        "            end=datetime.timedelta(seconds=segment[\"end\"]),\n",
        "            content=text\n",
        "        )\n",
        "    )\n",
        "    sub_index += 1\n",
        "\n",
        "# --- 4. SAVE FILE ---\n",
        "with open(output_srt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(srt.compose(final_subs))\n",
        "\n",
        "# Cleanup\n",
        "if os.path.exists(processed_audio):\n",
        "    os.remove(processed_audio)\n",
        "\n",
        "print(f\"------------------------------------------------\")\n",
        "print(f\"✅ Optimization Complete.\")\n",
        "print(f\"Saved: {output_srt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-3aBq_iR0oH",
        "outputId": "a76fc28f-a51f-400c-f82b-61879fc6018a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Optimizing audio for Voice Frequencies (1234.mp3)...\n",
            "2. Transcribing with Forced Alignment (DTW)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 187317/187317 [02:52<00:00, 1088.41frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Applying Japanese Garbage & Duration Filters...\n",
            "------------------------------------------------\n",
            "✅ Optimization Complete.\n",
            "Saved: output.srt\n"
          ]
        }
      ]
    }
  ]
}