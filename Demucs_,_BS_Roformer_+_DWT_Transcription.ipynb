{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasial2/JapaneseTranscription/blob/main/Demucs_%2C_BS_Roformer_%2B_DWT_Transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üõ†Ô∏è Step 1: Smart Installation (Select Engine)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# üéõÔ∏è INSTALL CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "# Choose which engine you intend to use in Step 2.\n",
        "# \"Demucs Only\": Fast installation. Best for quiet/conversational JAV.\n",
        "# \"BS-Roformer Only\": Slower install, heavier. Best for music/noise removal.\n",
        "# \"Install Both\": Installs everything (Takes longest).\n",
        "install_mode = \"BS-Roformer Only\" # @param [\"Demucs Only\", \"BS-Roformer Only\", \"Install Both\"]\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ INSTALLATION SCRIPT\n",
        "# ==========================================\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "print(f\"‚è≥ Initializing Setup for: {install_mode}...\")\n",
        "\n",
        "try:\n",
        "    # 1. ALWAYS INSTALL: Common Base Tools (Required for Step 3 & FFmpeg)\n",
        "    print(\"   -> Installing Core Tools (FFmpeg, Whisper, SRT)...\")\n",
        "    install(\"ffmpeg-python\")\n",
        "    install(\"soundfile\")\n",
        "    install(\"yt-dlp\")\n",
        "    install(\"whisper-timestamped\")\n",
        "    install(\"srt\")\n",
        "    install(\"tqdm\")\n",
        "\n",
        "    # 2. CONDITIONAL INSTALL: Demucs\n",
        "    if \"Demucs\" in install_mode or \"Both\" in install_mode:\n",
        "        print(\"   -> Installing Demucs...\")\n",
        "        install(\"demucs\")\n",
        "\n",
        "    # 3. CONDITIONAL INSTALL: BS-Roformer (UVR5)\n",
        "    if \"Roformer\" in install_mode or \"Both\" in install_mode:\n",
        "        print(\"   -> Installing BS-Roformer (Audio Separator)...\")\n",
        "        # This installs the GPU-accelerated version specifically\n",
        "        install(\"audio-separator[gpu]\")\n",
        "\n",
        "    print(\"‚úÖ Installation Complete.\")\n",
        "    print(f\"   ‚ÑπÔ∏è  Ready to use {install_mode} in Step 2.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Installation Failed: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pqYMsjFyw-IC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1fb95df1-4ff8-42ba-dbc8-426f9c023634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Initializing Setup for: BS-Roformer Only...\n",
            "   -> Installing Core Tools (FFmpeg, Whisper, SRT)...\n",
            "   -> Installing BS-Roformer (Audio Separator)...\n",
            "‚úÖ Installation Complete.\n",
            "   ‚ÑπÔ∏è  Ready to use BS-Roformer Only in Step 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üßπ Step 2: Dual-Engine Audio Mastering (Demucs / BS-Roformer)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "import ffmpeg\n",
        "import logging\n",
        "import subprocess\n",
        "import sys\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# üéõÔ∏è MASTER CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "input_filename = \"1234.mp3\" # @param {type:\"string\"}\n",
        "final_output_filename = \"1234_mastered.wav\" # @param {type:\"string\"}\n",
        "\n",
        "# --- ENGINE SELECTION ---\n",
        "# \"BS-Roformer\": Best for removing music/loud noise. Surgical precision.\n",
        "# \"Demucs (HT)\": Best for quiet rooms/conversations. Warmer, more natural.\n",
        "processing_engine = \"BS-Roformer (ViperX)\" # @param [\"BS-Roformer (ViperX)\", \"Demucs (HT)\"]\n",
        "\n",
        "# --- [DEMUCS ONLY] SETTINGS ---\n",
        "# \"Fast\": Good for quick checks. \"High Precision\": Best for complex overlap.\n",
        "demucs_quality = \"High Precision (4 Shifts)\" # @param [\"Fast (1 Shifts)\", \"Standard (2 Shifts)\", \"High Precision (4 Shifts)\"]\n",
        "\n",
        "# --- [ROFORMER ONLY] SETTINGS ---\n",
        "# \"ViperX-1297\": The SOTA model. \"MDX23C\": Faster fallback.\n",
        "roformer_model = \"ViperX-1297 (Best Quality)\" # @param [\"ViperX-1297 (Best Quality)\", \"MDX23C (Fast)\"]\n",
        "\n",
        "# --- MASTERING (APPLIES TO BOTH) ---\n",
        "# \"Conversation (LRA 7)\": Flattens volume so quiet actress = loud cameraman. (BEST FOR AI)\n",
        "# \"Balanced (LRA 9)\": A middle ground.\n",
        "# \"Natural (LRA 11)\": Broadcast standard. Keeps dynamics.\n",
        "audio_profile = \"Conversation (LRA 7) - Best for AI\" # @param [\"Conversation (LRA 7) - Best for AI\", \"Balanced (LRA 9)\", \"Natural (LRA 11) - Broadcast Standard\"]\n",
        "\n",
        "# ==========================================\n",
        "# ‚öôÔ∏è LOGIC PARSER (FIXED)\n",
        "# ==========================================\n",
        "\n",
        "# 1. Output Cleanup\n",
        "if not final_output_filename.endswith(\".wav\"):\n",
        "    final_output_filename += \".wav\"\n",
        "base_name = os.path.splitext(os.path.basename(input_filename))[0]\n",
        "temp_vocal_path = f\"temp_{base_name}_vocals.wav\"\n",
        "\n",
        "# 2. Parse LRA (Fixed Logic)\n",
        "if \"Conversation\" in audio_profile:\n",
        "    target_lra = 7\n",
        "elif \"Balanced\" in audio_profile:\n",
        "    target_lra = 9\n",
        "else:\n",
        "    target_lra = 11\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ MAIN EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "def run_demucs(in_file, out_file, quality_mode):\n",
        "    print(f\"\\nüîπ ENGINE: Running Demucs (HTDemucs)...\")\n",
        "    from demucs.pretrained import get_model\n",
        "    from demucs.apply import apply_model\n",
        "    import torchaudio\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Parse Quality (Fixed Logic)\n",
        "    if \"Fast\" in quality_mode:\n",
        "        shifts = 1\n",
        "    elif \"Standard\" in quality_mode:\n",
        "        shifts = 2\n",
        "    else:\n",
        "        shifts = 4 # High Precision\n",
        "\n",
        "    try:\n",
        "        model = get_model(\"htdemucs\")\n",
        "        model.to(device)\n",
        "\n",
        "        print(\"   -> Loading audio...\")\n",
        "        wav_np, sr = sf.read(in_file)\n",
        "        wav = torch.from_numpy(wav_np).float()\n",
        "\n",
        "        if len(wav.shape) == 1: wav = wav.unsqueeze(0)\n",
        "        else: wav = wav.t()\n",
        "\n",
        "        if sr != 44100:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 44100)\n",
        "            wav = resampler(wav)\n",
        "\n",
        "        ref = wav.mean(0)\n",
        "        wav = (wav - ref.mean()) / ref.std()\n",
        "        wav = wav.unsqueeze(0).to(device)\n",
        "\n",
        "        print(f\"   -> Separating (Shifts={shifts})...\")\n",
        "        sources = apply_model(model, wav, shifts=shifts, split=True, overlap=0.25, progress=True)\n",
        "        vocals = sources[0, 3].cpu().numpy()\n",
        "\n",
        "        sf.write(out_file, vocals.T, 44100)\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Demucs Error: {e}\")\n",
        "        raise\n",
        "\n",
        "def run_roformer(in_file, out_file, model_mode):\n",
        "    print(f\"\\nüîπ ENGINE: Running BS-Roformer (Audio Separator)...\")\n",
        "    from audio_separator.separator import Separator\n",
        "\n",
        "    # Select Model File\n",
        "    if \"ViperX\" in model_mode:\n",
        "        model_filename = \"model_bs_roformer_ep_317_sdr_12.9755.ckpt\"\n",
        "    else:\n",
        "        model_filename = \"UVR-MDX-NET-Inst_HQ_3.onnx\"\n",
        "\n",
        "    try:\n",
        "        # Initialize\n",
        "        separator = Separator(\n",
        "            log_level=logging.ERROR,\n",
        "            model_file_dir=\"/content/audio-separator-models/\",\n",
        "            output_dir=\"/content/\",\n",
        "            output_single_stem=\"vocals\"\n",
        "        )\n",
        "\n",
        "        print(f\"   -> Loading Model: {model_filename}\")\n",
        "        separator.load_model(model_filename=model_filename)\n",
        "\n",
        "        print(f\"   -> Inference...\")\n",
        "        output_files = separator.separate(in_file)\n",
        "\n",
        "        # Rename output to temp path\n",
        "        generated_file = output_files[0]\n",
        "        if os.path.exists(generated_file):\n",
        "            if os.path.exists(out_file): os.remove(out_file)\n",
        "            os.rename(generated_file, out_file)\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Roformer did not output a file.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Roformer Error: {e}\")\n",
        "        raise\n",
        "\n",
        "# --- MEMORY SAFETY CHECK ---\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "if not os.path.exists(input_filename):\n",
        "    print(f\"‚ùå Error: File '{input_filename}' not found!\")\n",
        "else:\n",
        "    print(f\"üöÄ Phase 1: Processing {input_filename}\")\n",
        "    print(f\"   ‚öôÔ∏è Engine: {processing_engine}\")\n",
        "    print(f\"   ‚öôÔ∏è Profile: {audio_profile} (LRA {target_lra})\")\n",
        "\n",
        "    # --- 1. RUN SEPARATION ---\n",
        "    try:\n",
        "        if \"Demucs\" in processing_engine:\n",
        "            run_demucs(input_filename, temp_vocal_path, demucs_quality)\n",
        "        else:\n",
        "            run_roformer(input_filename, temp_vocal_path, roformer_model)\n",
        "\n",
        "        print(f\"   ‚úÖ Vocal Isolation Complete.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Critical Separation Error: {e}\")\n",
        "        raise\n",
        "\n",
        "    # --- 2. RUN MASTERING (LOUDNORM) ---\n",
        "    print(f\"\\nüîπ [Phase 2] FFmpeg Broadcast Mastering...\")\n",
        "    try:\n",
        "        # FILTER EXPLANATION:\n",
        "        # highpass=90: Changed from 100 to 90 to be safer for deep male voices.\n",
        "        # loudnorm: Normalizes volume. LRA uses the variable we parsed above.\n",
        "        (\n",
        "            ffmpeg.input(temp_vocal_path)\n",
        "            .output(\n",
        "                final_output_filename,\n",
        "                acodec=\"pcm_s16le\", ac=1, ar=\"16000\",\n",
        "                af=f\"highpass=f=90,lowpass=f=8000,loudnorm=I=-16:TP=-1.5:LRA={target_lra}\"\n",
        "            )\n",
        "            .overwrite_output()\n",
        "            .run(quiet=True)\n",
        "        )\n",
        "        print(f\"   ‚úÖ Mastered File Ready: {final_output_filename}\")\n",
        "\n",
        "        # Cleanup\n",
        "        if os.path.exists(temp_vocal_path):\n",
        "            os.remove(temp_vocal_path)\n",
        "\n",
        "    except ffmpeg.Error as e:\n",
        "        print(\"   ‚ùå FFmpeg Error:\", e.stderr)\n",
        "        raise"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JMoMMhiswk7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d12be26-2ef4-4092-9328-ab069983d28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Phase 1: Processing 1234.mp3\n",
            "   ‚öôÔ∏è Engine: BS-Roformer (ViperX)\n",
            "   ‚öôÔ∏è Profile: Conversation (LRA 7) - Best for AI (LRA 7)\n",
            "\n",
            "üîπ ENGINE: Running BS-Roformer (Audio Separator)...\n",
            "   -> Loading Model: model_bs_roformer_ep_317_sdr_12.9755.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "28.3kiB [00:00, 29.3MiB/s]                  \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 639M/639M [00:06<00:00, 105MiB/s] \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.27k/2.27k [00:00<00:00, 3.97MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   -> Inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [12:13<00:00,  3.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úÖ Vocal Isolation Complete.\n",
            "\n",
            "üîπ [Phase 2] FFmpeg Broadcast Mastering...\n",
            "   ‚úÖ Mastered File Ready: 1234_mastered.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üßπ Step 2.5: Aggressive GPU Memory Nuke (Essential for BS-Roformer)\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "import sys\n",
        "\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Returns (allocated_mb, reserved_mb)\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "        return allocated, reserved\n",
        "    return 0, 0\n",
        "\n",
        "print(\"üõë INITIATING DEEP GPU CLEANING CYCLE...\")\n",
        "\n",
        "# --- 1. TARGETED ASSASSINATION OF VARIABLES ---\n",
        "# We explicitly hunt down the heavy objects from Step 2\n",
        "target_vars = [\n",
        "    'separator',      # BS-Roformer Object\n",
        "    'model',          # Demucs/Roformer Model\n",
        "    'wav',            # Audio Tensor\n",
        "    'sources',        # Demucs Output\n",
        "    'vocals',         # Raw Vocals\n",
        "    'resampler',      # Torchaudio resampler\n",
        "    'demucs',         # Demucs module alias\n",
        "    'wav_np'          # Numpy Audio\n",
        "]\n",
        "\n",
        "deleted_count = 0\n",
        "for var in target_vars:\n",
        "    if var in globals():\n",
        "        print(f\"   üî´ Killing variable: {var}\")\n",
        "        del globals()[var]\n",
        "        deleted_count += 1\n",
        "\n",
        "if deleted_count == 0:\n",
        "    print(\"   ‚ÑπÔ∏è  No heavy variables found in global scope (Clean slate).\")\n",
        "\n",
        "# --- 2. THE THREE-STAGE FLUSH LOOP ---\n",
        "# We loop because sometimes Python's GC needs multiple passes to catch cyclic references\n",
        "max_retries = 3\n",
        "clean_success = False\n",
        "\n",
        "for i in range(1, max_retries + 1):\n",
        "    print(f\"\\n   üîÑ [Cycle {i}/{max_retries}] Flushing Cache...\")\n",
        "\n",
        "    # 1. Force Python Garbage Collection (All Generations)\n",
        "    gc.collect()\n",
        "\n",
        "    # 2. Clear PyTorch CUDA Cache\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # 3. Clear IPC (Inter-Process Communication) - often forgotten\n",
        "    torch.cuda.ipc_collect()\n",
        "\n",
        "    # Verification\n",
        "    allocated, reserved = get_gpu_memory()\n",
        "    print(f\"      üìâ Current Status -> Allocated: {allocated:.2f}MB | Reserved: {reserved:.2f}MB\")\n",
        "\n",
        "    # Threshold: If we are under 1000MB reserved, we are effectively empty\n",
        "    if reserved < 1000:\n",
        "        clean_success = True\n",
        "        break\n",
        "\n",
        "# --- 3. FINAL VERDICT ---\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "final_alloc, final_reserved = get_gpu_memory()\n",
        "\n",
        "if clean_success or final_reserved < 1000:\n",
        "    print(f\"‚úÖ GPU CLEAN SUCCESSFUL\")\n",
        "    print(f\"   üß† VRAM Available for Whisper: ~14GB (on T4)\")\n",
        "    print(f\"   üìä Final 'Junk' Usage: {final_reserved:.2f}MB (Negligible)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è GPU CLEAN WARNING: PERSISTENT MEMORY DETECTED\")\n",
        "    print(f\"   üìä VRAM still holding: {final_reserved:.2f}MB\")\n",
        "    print(\"   üõë SUGGESTION: If Step 3 crashes, go to 'Runtime' -> 'Restart Session' and skip Step 2.\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nCKuJW39xtev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "323fe891-9360-4fc6-9c83-12a0e0387721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõë INITIATING DEEP GPU CLEANING CYCLE...\n",
            "   ‚ÑπÔ∏è  No heavy variables found in global scope (Clean slate).\n",
            "\n",
            "   üîÑ [Cycle 1/3] Flushing Cache...\n",
            "      üìâ Current Status -> Allocated: 9.12MB | Reserved: 22.00MB\n",
            "\n",
            "==============================\n",
            "‚úÖ GPU CLEAN SUCCESSFUL\n",
            "   üß† VRAM Available for Whisper: ~14GB (on T4)\n",
            "   üìä Final 'Junk' Usage: 22.00MB (Negligible)\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß† Step 3.1: Load Whisper Model (Smart Selection)\n",
        "\n",
        "import whisper_timestamped as whisper\n",
        "import torch\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "# ==========================================\n",
        "# üéõÔ∏è MODEL SELECTION GUIDE\n",
        "# ==========================================\n",
        "\n",
        "# Choose based on your video content:\n",
        "# 1. v3: Has the best vocabulary for Story/Plot. BUT it often hallucinates text during moaning scenes.\n",
        "# 2. v2: OLDER BUT SAFER. It ignores breathing/moaning better. Use this if v3 gives you garbage.\n",
        "# 3. Turbo: Very fast, but lower accuracy. Good for checking sync.\n",
        "model_variant = \"large-v3 (Best for Story/Plot - High Vocab)\" # @param [\"large-v3 (Best for Story/Plot - High Vocab)\", \"large-v2 (Stable - Best for Heavy Breathing/Moans)\", \"large-v3-turbo (Fastest - Lower Accuracy)\"]\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ LOAD LOGIC\n",
        "# ==========================================\n",
        "\n",
        "# Parse the user's choice to get the actual model name\n",
        "model_size = model_variant.split()[0]\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.hub\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"üöÄ Initializing Whisper...\")\n",
        "print(f\"   ‚ÑπÔ∏è  Selected Profile: {model_variant}\")\n",
        "\n",
        "try:\n",
        "    # 1. Check if model is already loaded\n",
        "    if 'loaded_model' in globals():\n",
        "        print(f\"‚ö†Ô∏è A model is already loaded in memory.\")\n",
        "        print(f\"   To switch models, you must Restart Runtime (Runtime -> Restart Session).\")\n",
        "        print(f\"   Otherwise, proceed to Step 3.2.\")\n",
        "\n",
        "    else:\n",
        "        # 2. Memory Safety Check\n",
        "        if torch.cuda.is_available():\n",
        "            free_mem = torch.cuda.mem_get_info()[0] / 1024**3\n",
        "            print(f\"   üß† VRAM Available: {free_mem:.2f} GB\")\n",
        "            if free_mem < 4.0:\n",
        "                print(\"   ‚ö†Ô∏è WARNING: VRAM is critically low. Did you run Step 2.5?\")\n",
        "\n",
        "        # 3. Load the Model\n",
        "        print(f\"   ‚è≥ Downloading & Loading '{model_size}'... (This happens once)\")\n",
        "        loaded_model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "        print(f\"‚úÖ Model Loaded Successfully!\")\n",
        "\n",
        "        # 4. Specific Advice based on selection\n",
        "        if \"large-v3\" in model_size:\n",
        "            print(\"   üí° TIP: You chose v3. If you see 'Thank you for watching' loops,\")\n",
        "            print(\"      increase the 'logprob_threshold' in Step 3.2.\")\n",
        "        elif \"large-v2\" in model_size:\n",
        "            print(\"   üí° TIP: You chose v2. It is very stable for JAV.\")\n",
        "            print(\"      It might miss some whispery dialects, but it won't hallucinate as much.\")\n",
        "\n",
        "        print(\"‚¨áÔ∏è  Proceed to Step 3.2.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load model: {e}\")\n",
        "    print(\"   üí° Tip: If OutOfMemory error, restart runtime and skip Step 2 (assuming audio is saved).\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zZE0LXjwzVFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "997ba859-88ee-4163-86dd-270ee619d325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing the dtw module. When using in academic works please cite:\n",
            "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
            "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
            "\n",
            "üöÄ Initializing Whisper...\n",
            "   ‚ÑπÔ∏è  Selected Profile: large-v3 (Best for Story/Plot - High Vocab)\n",
            "   üß† VRAM Available: 14.59 GB\n",
            "   ‚è≥ Downloading & Loading 'large-v3'... (This happens once)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.88G/2.88G [00:57<00:00, 54.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model Loaded Successfully!\n",
            "   üí° TIP: You chose v3. If you see 'Thank you for watching' loops,\n",
            "      increase the 'logprob_threshold' in Step 3.2.\n",
            "‚¨áÔ∏è  Proceed to Step 3.2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üìù Step 3.2: Transcribe & Download (Fixed & Robust)\n",
        "\n",
        "import srt\n",
        "import datetime\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "from google.colab import files\n",
        "\n",
        "# ==========================================\n",
        "# üéõÔ∏è USER CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "# --- FILES ---\n",
        "audio_file_to_transcribe = \"1234_mastered.wav\" # @param {type:\"string\"}\n",
        "output_srt = \"1234.srt\" # @param {type:\"string\"}\n",
        "\n",
        "# --- EXTERNAL VAD (Silero) ---\n",
        "# [TRUE] = \"Hard Mode\". Cuts non-speech audio before Whisper hears it.\n",
        "#          Fixes hallucinations but might cut soft \"Ya...\" sounds.\n",
        "# [FALSE] = \"Soft Mode\". Relies on Whisper's internal logic. Safer for JAV.\n",
        "enable_silero_vad = False # @param {type:\"boolean\"}\n",
        "\n",
        "vad=\"False\" # @param [\"True\", \"False\"]\n",
        "\n",
        "# --- WHISPER SENSITIVITY (Internal Logic) ---\n",
        "# \"High Sensitivity\": Captures whispers/breathing (Effectively VAD=OFF).\n",
        "# \"Balanced\": Standard behavior.\n",
        "# \"Strict\": Ignores ambiguous sounds (Effectively VAD=ON).\n",
        "internal_sensitivity = \"High Sensitivity (Plot/Whispers)\" # @param [\"High Sensitivity (Plot/Whispers)\", \"Balanced (Standard)\", \"Strict (Action/No Moans)\"]\n",
        "\n",
        "# --- HALLUCINATION GUARD ---\n",
        "# \"Strict\": Deletes text if confidence is low. Prevents loops.\n",
        "hallucination_guard = \"Strict (Anti-Loop)\" # @param [\"Strict (Anti-Loop)\", \"Permissive (Allow Mumbling)\"]\n",
        "\n",
        "# --- GENRE CONTEXT ---\n",
        "genre_context = \"Standard JAV (Casual/Conversational)\" # @param [\"Standard JAV (Casual/Conversational)\", \"Hardcore (More yelling/moaning)\", \"Dialect/Kansai (Regional Speech)\"]\n",
        "\n",
        "# ==========================================\n",
        "# ‚öôÔ∏è LOGIC PARSER & SAFETY CHECKS\n",
        "# ==========================================\n",
        "\n",
        "# Map string 'vad' parameter to boolean 'use_silero_vad'\n",
        "use_silero_vad = True if vad == \"True\" else False\n",
        "\n",
        "# 1. Parse Internal Sensitivity (no_speech_threshold)\n",
        "if \"High\" in internal_sensitivity:\n",
        "    speech_threshold = 0.25\n",
        "elif \"Strict\" in internal_sensitivity:\n",
        "    speech_threshold = 0.6\n",
        "else:\n",
        "    speech_threshold = 0.4\n",
        "\n",
        "# 2. Parse Hallucination Guard (logprob_threshold)\n",
        "if \"Strict\" in hallucination_guard:\n",
        "    logprob_cutoff = -0.7\n",
        "else:\n",
        "    logprob_cutoff = -1.0\n",
        "\n",
        "# 3. Build Prompt\n",
        "base_prompt = \"‰ºöË©±„ÅÆ„Åø„ÇíÊõ∏„ÅçËµ∑„Åì„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂëºÂê∏Èü≥„ÄÅ„ÅÇ„Åà„ÅéÂ£∞„ÅØÁÑ°Ë¶ñ„ÄÇ\"\n",
        "if \"Standard\" in genre_context:\n",
        "    final_prompt = base_prompt + \"„Çø„É°Âè£„ÄÅÊó•Â∏∏‰ºöË©±„ÄÇ„ÇÑ„ÄÅ„ÅÑ„ÇÑ„ÄÅ„ÅÜ„Çì„ÄÅ„Åô„Åî„ÅÑ„ÄÅÊ∞óÊåÅ„Å°„ÅÑ„ÅÑ„ÄÅ„ÅØ„ÅÑ„ÄÇ\"\n",
        "elif \"Hardcore\" in genre_context:\n",
        "    final_prompt = base_prompt + \"ÂëΩ‰ª§ÂΩ¢„ÄÅÊøÄ„Åó„ÅÑË®ÄËëâÈÅ£„ÅÑ„ÄÇ„ÇÑ„ÇÅ„Å¶„ÄÅ„Å†„ÇÅ„ÄÅË®±„Åó„Å¶„ÄÅ„Ç§„Åè„ÄÇ\"\n",
        "else:\n",
        "    final_prompt = base_prompt + \"Èñ¢Ë•øÂºÅ„ÄÅÂ§ßÈò™ÂºÅ„ÄÅÊñπË®Ä„ÄÇ„Åª„Çì„Åæ„ÄÅ„Å™„Çì„Åß„ÄÅ„Å°„ÇÉ„ÅÜ„ÄÅ„Åõ„ÇÑ„Å™„ÄÇ\"\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ MAIN SCRIPT\n",
        "# ==========================================\n",
        "\n",
        "def format_timedelta(seconds):\n",
        "    return datetime.timedelta(seconds=seconds)\n",
        "\n",
        "def cleanup_text(text):\n",
        "    return re.sub(r'[\\W_]+', '', text.lower())\n",
        "\n",
        "# Check Dependencies\n",
        "if 'loaded_model' not in globals():\n",
        "    print(\"‚ùå Error: Model not loaded! Please run Step 3.1 first.\")\n",
        "elif not os.path.exists(audio_file_to_transcribe):\n",
        "    print(f\"‚ùå Error: File '{audio_file_to_transcribe}' not found!\")\n",
        "    print(\"   ‚ÑπÔ∏è  Please check the filename you set in Step 2.\")\n",
        "else:\n",
        "    print(f\"\\nüîπ Transcribing: {audio_file_to_transcribe}\")\n",
        "    print(f\"   ‚öôÔ∏è  Silero VAD: {use_silero_vad}\")\n",
        "    print(f\"   ‚öôÔ∏è  Internal Logic: {internal_sensitivity} (Thresh: {speech_threshold})\")\n",
        "\n",
        "    try:\n",
        "        # 1. RUN WHISPER\n",
        "        result = whisper.transcribe(\n",
        "            loaded_model,\n",
        "            audio_file_to_transcribe,\n",
        "            language=\"ja\",\n",
        "\n",
        "            # Accuracy\n",
        "            beam_size=5,\n",
        "            best_of=5,\n",
        "            temperature=0.0,\n",
        "\n",
        "            # Sync\n",
        "            trust_whisper_timestamps=False,\n",
        "\n",
        "            # --- VAD SETTINGS ---\n",
        "            vad=use_silero_vad,\n",
        "            no_speech_threshold=speech_threshold,\n",
        "\n",
        "            # --- GUARD RAILS ---\n",
        "            logprob_threshold=logprob_cutoff,\n",
        "            compression_ratio_threshold=2.2,\n",
        "\n",
        "            # Context\n",
        "            detect_disfluencies=True,\n",
        "            condition_on_previous_text=False,\n",
        "            initial_prompt=final_prompt\n",
        "        )\n",
        "        print(\"   ‚úÖ Transcription Complete. Filtering...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Transcription Error: {e}\")\n",
        "        if \"out of memory\" in str(e).lower():\n",
        "            print(\"   ‚ö†Ô∏è OOM: Restart Runtime -> Step 2.5 -> Step 3.1 (Use v2)\")\n",
        "        raise\n",
        "\n",
        "    # 2. FILTERS (JAV OPTIMIZED)\n",
        "    hallucination_triggers = [\n",
        "        \"thank you for watching\", \"thanks for watching\", \"please subscribe\",\n",
        "        \"subscribe\", \"sub by\", \"translated by\", \"amara\", \"viewing\",\n",
        "        \"see you next\", \"bye\", \"the end\", \"like and\", \"follow me\",\n",
        "        \"Â≠óÂπï\", \"Ë¶ñËÅ¥\", \"„ÉÅ„É£„É≥„Éç„É´\", \"ÁôªÈå≤\", \"È´òË©ï‰æ°\"\n",
        "    ]\n",
        "\n",
        "    # Safe Garbage List\n",
        "    garbage_exact_matches = {\n",
        "        \"aa\", \"ah\", \"ahh\", \"haa\", \"hah\", \"haha\", \"mm\", \"mmm\", \"hmm\",\n",
        "        \"oh\", \"huh\", \"o\", \"m\", \"h\", \"eh\", \"uh\", \"uhh\",\n",
        "        \"„ÅÇ\", \"„ÅÇ„ÅÇ\", \"„ÅÇ„Å£\", \"„ÅÇ„Éº\", \"„Çì„Çì\", \"„ÅÜ\", \"„ÅÜ„Å£\",\n",
        "        \"„ÅØ„ÅÅ\", \"„ÅØ„ÅÇ\", \"„Åµ\", \"„Åµ„ÅÖ\", \"„Åè\", \"„Åè„Å£\"\n",
        "    }\n",
        "\n",
        "    final_subs = []\n",
        "    sub_index = 1\n",
        "\n",
        "    for segment in result[\"segments\"]:\n",
        "        text = segment[\"text\"].strip()\n",
        "        text_lower = text.lower()\n",
        "        duration = segment[\"end\"] - segment[\"start\"]\n",
        "\n",
        "        if duration < 0.2: continue\n",
        "        if any(h in text_lower for h in hallucination_triggers): continue\n",
        "\n",
        "        clean = cleanup_text(text_lower)\n",
        "        words = clean.split()\n",
        "        if not words: continue\n",
        "\n",
        "        is_garbage = True\n",
        "        for w in words:\n",
        "            if w not in garbage_exact_matches:\n",
        "                is_garbage = False\n",
        "                break\n",
        "        if is_garbage: continue\n",
        "\n",
        "        if len(words) > 4 and len(set(words)) == 1: continue\n",
        "\n",
        "        final_subs.append(\n",
        "            srt.Subtitle(\n",
        "                index=sub_index,\n",
        "                start=format_timedelta(segment[\"start\"]),\n",
        "                end=format_timedelta(segment[\"end\"]),\n",
        "                content=text\n",
        "            )\n",
        "        )\n",
        "        sub_index += 1\n",
        "\n",
        "    # 3. SAVE & DOWNLOAD\n",
        "    with open(output_srt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(srt.compose(final_subs))\n",
        "\n",
        "    print(f\"   üíæ Saved: {output_srt}\")\n",
        "    try:\n",
        "        files.download(output_srt)\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Manual Download Required: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "cellView": "form",
        "id": "Ig7Da4STqgGb",
        "outputId": "e5ed0850-59c6-491e-dd5c-3c9b9c3958ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Transcribing: 1234_mastered.wav\n",
            "   ‚öôÔ∏è  Silero VAD: False\n",
            "   ‚öôÔ∏è  Internal Logic: High Sensitivity (Plot/Whispers) (Thresh: 0.25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 173690/191690 [08:34<00:53, 337.77frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úÖ Transcription Complete. Filtering...\n",
            "   üíæ Saved: 1234.srt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_547e025c-6546-4c6b-ac66-b98f12598dd3\", \"1234.srt\", 33049)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üßπ Step 3.3: Clear GPU Memory\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "print(\"üßπ Cleaning up GPU memory...\")\n",
        "\n",
        "if 'loaded_model' in globals():\n",
        "    del loaded_model\n",
        "    print(\"   ‚úÖ Model deleted from memory.\")\n",
        "else:\n",
        "    print(\"   ‚ÑπÔ∏è No model was loaded.\")\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"‚úÖ Memory Cleared!\")\n",
        "print(\"üîÑ You can now run Step 2 again for a new file.\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHY1ZbK06KvZ",
        "outputId": "b7a5e2cf-a277-45ed-ddb6-481f485f8867",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning up GPU memory...\n",
            "   ‚úÖ Model deleted from memory.\n",
            "‚úÖ Memory Cleared!\n",
            "üîÑ You can now run Step 2 again for a new file.\n"
          ]
        }
      ]
    }
  ]
}